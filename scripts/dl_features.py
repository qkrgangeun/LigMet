import numpy as np
from pathlib import Path
from ligmet.utils.pdb import read_pdb # type: ignore
from ligmet.featurizer import * # type: ignore
from ligmet.utils.grid import * # type: ignore
from dataclasses import asdict
import traceback
import argparse
# ì…ë ¥ ë° ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
pdb_dir = Path('/home/qkrgangeun/LigMet/data/biolip/pdb')  # PDB íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
output_dir = Path('/home/qkrgangeun/LigMet/data/biolip/dl/features')  # .npz ì €ì¥í•  ë””ë ‰í† ë¦¬
#metalpred
# pdb_dir = Path('/home/qkrgangeun/MetalPred/data/biolip_group/latest')  # PDB íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
# output_dir = Path('/home/qkrgangeun/LigMet/data/metalpred/dl/features')  

output_dir.mkdir(parents=True, exist_ok=True)  # ì €ì¥ í´ë” ìƒì„± (ì—†ìœ¼ë©´ ìƒì„±)

def bondmask_to_neighidx(bond_mask: np.ndarray):
    rows, cols = np.where(np.triu(bond_mask) > 0)
    return np.stack([rows, cols], axis=0).astype(np.int32)

def optimize_dtype(key, arr):
    if key == "bond_masks":
        return bondmask_to_neighidx(arr)

    elif key in ["atom_positions", "metal_positions", "grid_positions", "qs", "sasas"]:
        return arr.astype(np.float32)

    elif key == "residue_idxs":
        return arr.astype(np.int32)

    elif key in ["sec_structs", "gen_types"]:
        return arr.astype(np.int16)

    elif key == "is_ligand":
        return arr.astype(np.bool_)

    elif isinstance(arr, np.ndarray) and arr.dtype.kind == "U":
        maxlen = max(len(str(s)) for s in arr)
        return arr.astype(f"<U{maxlen}")

    return arr  # ê·¸ëŒ€ë¡œ

def process_pdb(pdb_id):
    """ ê°œë³„ PDB íŒŒì¼ì„ ì²˜ë¦¬í•˜ê³  .npzë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ """
    pdb_path = pdb_dir / f"{pdb_id}.pdb"
    output_npz_path = output_dir / f"{pdb_path.stem}.npz"
    if output_npz_path.exists():
        print(f"already exit Skip: {pdb_path.name}")
        return
    try:
        print(f"ğŸ“‚ Processing: {pdb_path.name}")

        # PDB ë°ì´í„° ì½ê¸°
        structure = read_pdb(pdb_path)
        if len(structure.atom_positions) > 50000:
            print("skip more than 50000")
            return
        else:
            # Grid ìƒì„± ë° í•„í„°ë§
            grids = sasa_grids_thread(structure.atom_positions, structure.atom_elements)
            grids = filter_by_clashmap(grids)

            # StructureWithGrid ìƒì„±
            structure_dict = asdict(structure)
            structure_with_grid = StructureWithGrid(
                grid_positions=grids,
                **structure_dict
            )

            # Features ìƒì„±
            features = make_features(pdb_path, structure_with_grid)

            # `.npz` íŒŒì¼ë¡œ ì €ì¥í•  ê²½ë¡œ ì„¤ì •

            # ì €ì¥í•  ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            feature_dict = {
                k: optimize_dtype(k, v)
                for k, v in asdict(features).items()
                if isinstance(v, np.ndarray)
            }

            # `.npz` íŒŒì¼ë¡œ ì••ì¶• ì €ì¥
            np.savez(output_npz_path, **feature_dict)

            print(f"âœ… {pdb_path.name} ì²˜ë¦¬ ì™„ë£Œ â†’ ì €ì¥ë¨: {output_npz_path}")

    except Exception as e:
        print(f"âŒ {pdb_path.name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()  # ìƒì„¸ ì˜¤ë¥˜ ì¶œë ¥

# ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('pdb_id', type=str )
    args = parser.parse_args()
    pdb_id = args.pdb_id
    process_pdb(pdb_id)

