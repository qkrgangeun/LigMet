{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch  # type: ignore\n",
    "import dgl  # type: ignore\n",
    "from scipy.spatial import cKDTree  # type: ignore\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F  # type: ignore\n",
    "from typing import Tuple, Union\n",
    "from ligmet.featurizer import Features, Info # type: ignore\n",
    "from ligmet.utils.constants import metals, standard_residues,ATOMIC_NUMBERS, atype2num,sec_struct_dict  # type: ignore\n",
    "class PreprocessedDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_file: str, features_dir: str, rf_result_dir: str,topk: 16, edge_dist_cutoff: 3.0, pocket_dist: 6.0, rf_threshold: 0.5, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.data_file=Path(data_file)\n",
    "        self.features_dir=Path(features_dir)\n",
    "        self.rf_result_dir=Path(rf_result_dir)\n",
    "        self.topk = topk\n",
    "        self.edge_dist_cutoff=edge_dist_cutoff\n",
    "        self.pocket_dist=pocket_dist\n",
    "        self.rf_threshold=rf_threshold\n",
    "        self.pdbid_lists=[pdb.strip().split(\".pdb\")[0] for pdb in open(data_file)]\n",
    "        self.eps = eps\n",
    "        self.alpha = 5.78\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pdbid_lists)\n",
    "    \n",
    "    def __getitem__(self, index:int):\n",
    "        G = []\n",
    "        L = []\n",
    "        pdb_id = self.pdbid_lists[index]\n",
    "        feature_path = self.features_dir / f\"{pdb_id}.npz\"\n",
    "        rf_result_path = self.rf_result_dir / f\"{pdb_id}.npz\"\n",
    "        data = np.load(feature_path,allow_pickle=True)\n",
    "        features = Features(\n",
    "            atom_positions=data['atom_positions'],\n",
    "            atom_names=data['atom_names'],\n",
    "            atom_elements=data['atom_elements'],\n",
    "            atom_residues=data['atom_residues'],\n",
    "            residue_idxs=data['residue_idxs'],\n",
    "            chain_ids=data['chain_ids'],\n",
    "            is_ligand=data['is_ligand'],\n",
    "            metal_positions=data['metal_positions'],\n",
    "            metal_types=data['metal_types'],\n",
    "            grid_positions=data['grid_positions'],\n",
    "            sasas=data['sasa'],\n",
    "            qs=data['qs'],\n",
    "            sec_structs=data['sec_structs'],\n",
    "            bond_masks=data['bond_masks']\n",
    "        )\n",
    "        grid_positions = features.grid_positions\n",
    "        grid_probs = np.load(rf_result_path)\n",
    "        grid_mask = grid_probs >= self.rf_threshold\n",
    "        grids_after_rf = grid_positions[grid_mask]\n",
    "        features_p, pocket_exist = self.find_pocket(features, grids_after_rf)\n",
    "        \n",
    "        if pocket_exist is False:\n",
    "            raise AttributeError(\"there is no grids after randomforest\")\n",
    "        \n",
    "        g = self.make_graph(features_p)\n",
    "        l_prob, l_type, l_vector = self.make_label(features_p)\n",
    "        labels = torch.cat([l_prob.unsqueeze(1), l_type.unsqueeze(1), l_vector], dim=1)  # shape [N,5]\n",
    "        G.append(g)\n",
    "        L.append(labels)\n",
    "        if not G:\n",
    "            raise AttributeError(f\"{pdb_id} have none type graph\")\n",
    "        info = Info(\n",
    "            pdb_id=np.array(pdb_id),\n",
    "            grids_positions=torch.tensor(grids_after_rf, dtype=torch.float32),\n",
    "            metal_positions=torch.tensor(features.metal_positions, dtype=torch.float32),\n",
    "            metal_types=torch.tensor(features.metaltype, dtype=torch.long),\n",
    "        )\n",
    "        return G, L, info\n",
    "\n",
    "    def find_pocket(self, features: Features, grids: np.ndarray):\n",
    "        c_grids = grids\n",
    "        atom_pos = features.atom_positions\n",
    "\n",
    "        gtree = cKDTree(c_grids)\n",
    "        ptree = cKDTree(atom_pos)\n",
    "        ii = gtree.query_ball_tree(ptree, self.pocket_dist)\n",
    "\n",
    "        idx = np.unique(np.concatenate([i for i in ii if i], axis=0)).astype(int)\n",
    "        if len(idx) == 0:\n",
    "            return None, False\n",
    "\n",
    "        c_features = Features(\n",
    "            atom_positions=atom_pos[idx],\n",
    "            atom_names=features.atom_names[idx],\n",
    "            atom_elements=features.atom_elements[idx],\n",
    "            atom_residues=features.atom_residues[idx],\n",
    "            residue_idxs=features.residue_idxs[idx],\n",
    "            chain_ids=features.chain_ids[idx],\n",
    "            is_ligand=features.is_ligand[idx],\n",
    "            metal_positions=features.metal_positions, \n",
    "            metal_types=features.metal_types,\n",
    "            grid_positions=c_grids,\n",
    "            sasas=features.sasas[idx],\n",
    "            qs=features.qs[idx],\n",
    "            sec_structs=features.sec_structs[idx],\n",
    "            bond_masks=features.bond_masks[np.ix_(idx, idx)], \n",
    "        )\n",
    "\n",
    "        return c_features, True\n",
    "    \n",
    "    def make_label(self, features:Features)->Union[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        grid = np.array(features.grid_positions, dtype=np.float32)\n",
    "        grids = torch.from_numpy(grid)\n",
    "        metal_pos = torch.from_numpy(features.metal_positions)\n",
    "        metal_types = torch.from_numpy(features.metaltype)\n",
    "\n",
    "        diff = grids.unsqueeze(1) - metal_pos.unsqueeze(0)  # [g,m,3]\n",
    "        dist = torch.sqrt(torch.sum(diff**2, dim=-1)) + self.eps  # [g,m]\n",
    "\n",
    "        exp_dist = torch.exp(-(dist**2) / self.alpha)\n",
    "        label_p, _ = torch.max(exp_dist, dim=-1)\n",
    "        label_prob = torch.where(label_p <= 0.1, torch.tensor(0.0), label_p)\n",
    "\n",
    "        min_dist, min_idx = torch.min(dist, dim=-1)  # [g,]\n",
    "        label_type = torch.where(\n",
    "            min_dist <= 2.0, metal_types[min_idx], torch.tensor(len(metals))\n",
    "        )\n",
    "        label_vector = diff[torch.arange(diff.size(0)), min_idx]\n",
    "        \n",
    "        return label_prob, label_type, label_vector\n",
    "    \n",
    "    def make_graph(self, features: Features) -> dgl.DGLGraph:\n",
    "        xyz = torch.tensor(np.concatenate([features.atom_positions, features.grid_positions]))\n",
    "        grid_mask = torch.ones(len(xyz))\n",
    "        grid_mask[: len(features.sasas)] = 0\n",
    "        n_feats, n_polar_vec = self.get_node_features(features)\n",
    "        num_nodes = xyz.shape[0]\n",
    "        edge_index_src, edge_index_dst, e_feats, rel_vec = self.make_edge(features)\n",
    "        G = dgl.graph((edge_index_src.to(torch.int32), edge_index_dst.to(torch.int32)),num_nodes=num_nodes)\n",
    "        G.ndata[\"xyz\"] = xyz.to(torch.float32)\n",
    "        G.ndata[\"L0\"] = n_feats.to(torch.float32)\n",
    "        G.ndata[\"L1\"] = n_polar_vec.to(torch.float32)\n",
    "        G.ndata[\"grid_mask\"] = grid_mask.to(torch.float32)\n",
    "        G.edata[\"L0\"] = e_feats.to(torch.float32)\n",
    "        G.edata[\"L1\"] = rel_vec.to(torch.float32)\n",
    "        \n",
    "        return G\n",
    "    \n",
    "    def make_polarity_vector(self, features: Features) -> np.ndarray:\n",
    "        xyz = torch.from_numpy(features.atom_positions)\n",
    "        neigh_masks = torch.from_numpy(features.bond_masks)\n",
    "\n",
    "        self_idx, nei_idx = torch.nonzero(neigh_masks, as_tuple=True)\n",
    "\n",
    "        xyz_self = xyz * neigh_masks.sum(dim=1, keepdim=True)\n",
    "        xyz_nei = -xyz[nei_idx]\n",
    "        xyz_self.scatter_add_(0, self_idx[:, None].expand(-1, 3), xyz_nei)\n",
    "\n",
    "        polar_vec = F.normalize(xyz_self, dim=1)\n",
    "        polarity_vectors = torch.cat(\n",
    "            [polar_vec, torch.zeros(features.grid_positions.shape)], dim=0\n",
    "        ).numpy()\n",
    "        return polarity_vectors\n",
    "\n",
    "    def get_node_features(self, features: Features) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # num_res = len(features.atom_names)\n",
    "        num_grids = len(features.grid_positions)\n",
    "\n",
    "        sasas = torch.from_numpy(features.sasas)\n",
    "        qs = torch.from_numpy(features.qs)\n",
    "        sec_structs = torch.from_numpy(features.sec_structs)\n",
    "        aatype = torch.from_numpy(features.atom_residues)\n",
    "        atom_chem_type = torch.from_numpy(features.atom_elements)\n",
    "        \n",
    "        # one hot features: aatype, atomtype, 2nd structures\n",
    "        # assign max int for grids\n",
    "        aatype = [standard_residues.index(res) if res in standard_residues else len(standard_residues) for res in features.atom_residues ]\n",
    "        grids_aatype = torch.ones(num_grids) * len(standard_residues)+1\n",
    "        aatype = torch.cat((aatype, grids_aatype))\n",
    "\n",
    "        atomtype = torch.from_list([ATOMIC_NUMBERS.get(elem,119) for elem in features.atom_elements])\n",
    "        grids_atomtype = torch.zeros(num_grids)\n",
    "        atomtype = torch.cat([atomtype, grids_atomtype], dim=0)\n",
    "        \n",
    "        ##TODO: ligand gentype\n",
    "        grids_atomchemtype = torch.ones(num_grids) * len(atype2num)\n",
    "        atom_chem_type = torch.cat([atom_chem_type, grids_atomchemtype], dim=0)\n",
    "        \n",
    "        grids_2nd = torch.ones(num_grids) * len(sec_struct_dict)\n",
    "        sec_structs = torch.cat([sec_structs, grids_2nd])\n",
    "\n",
    "        # one-hot encoding\n",
    "        aatype = F.one_hot(aatype.to(torch.int64), num_classes=len(standard_residues) + 2)\n",
    "        atomtype = F.one_hot(atomtype.to(torch.int64), num_classes=len(ATOMIC_NUMBERS) + 2)\n",
    "        sec_structs = F.one_hot(\n",
    "            sec_structs.to(torch.int64), num_classes=len(sec_struct_dict) + 1\n",
    "        )\n",
    "        atom_chemtype = F.one_hot(\n",
    "            atom_chem_type.to(torch.int64), num_classes=len(atype2num) + 1\n",
    "        )\n",
    "        # real value features: sasas, qs\n",
    "        # assign 0 for grids\n",
    "        grids_feat = torch.zeros(num_grids)\n",
    "        sasas = torch.cat((sasas, grids_feat)).unsqueeze(-1)\n",
    "        qs = torch.cat((qs, grids_feat)).unsqueeze(-1)\n",
    "        # sasas can have nan value\n",
    "        sasas = sasas + self.eps\n",
    "\n",
    "        n_feats = torch.cat(\n",
    "            [aatype, atomtype, atom_chemtype, sec_structs, sasas, qs], dim=1\n",
    "        )\n",
    "        print(\n",
    "            \"aatype, atomtype, atom_chemtype, sec-str, sasas, qs)\",\n",
    "            aatype.shape,\n",
    "            atomtype.shape,\n",
    "            atom_chemtype.shape,\n",
    "            sec_structs.shape,\n",
    "            sasas.shape,\n",
    "            qs.shape,\n",
    "        )\n",
    "        polarity_vectors = self.make_polarity_vector(features)\n",
    "        polarity_vectors = torch.tensor(polarity_vectors)\n",
    "        return n_feats, polarity_vectors\n",
    "\n",
    "    def onehot_edge_dist(self, dists: torch.Tensor) -> torch.Tensor:\n",
    "        bin_edges = np.arange(0, self.dist_cutoff + 0.5, 0.5)\n",
    "        dist_binned = np.digitize(dists, bins=bin_edges) - 1\n",
    "        one_hot_dist = F.one_hot(\n",
    "            torch.from_numpy(dist_binned), num_classes=len(bin_edges)\n",
    "        )\n",
    "        return one_hot_dist\n",
    "\n",
    "    def onehot_edge_type(\n",
    "        self, edge_index_src: torch.Tensor, edge_index_dst: torch.Tensor, num_atom: int\n",
    "    ) -> torch.Tensor:\n",
    "        feat = np.zeros_like(edge_index_src)  # p to p :0\n",
    "        feat[np.where((edge_index_src < num_atom) & (edge_index_dst >= num_atom))] = (\n",
    "            1  # p to g :1\n",
    "        )\n",
    "        feat[np.where((edge_index_src >= num_atom) & (edge_index_dst < num_atom))] = (\n",
    "            2  # g to p : 2\n",
    "        )\n",
    "        feat[np.where((edge_index_src >= num_atom) & (edge_index_dst >= num_atom))] = (\n",
    "            3  # g to g :3\n",
    "        )\n",
    "        one_hot_feat = F.one_hot(torch.from_numpy(feat).to(torch.int64), num_classes=4)\n",
    "        return one_hot_feat\n",
    "\n",
    "    def cov_bond(\n",
    "        self,\n",
    "        edge_index_src: torch.Tensor,\n",
    "        edge_index_dst: torch.Tensor,\n",
    "        num_atom: int,\n",
    "        features: Features,\n",
    "    ) -> torch.Tensor:\n",
    "        # shape (edge, )\n",
    "        cov_bond = np.zeros(len(edge_index_src))\n",
    "        prot_idx_mask = (edge_index_src < num_atom) & (edge_index_dst < num_atom)\n",
    "        idx = (edge_index_src[prot_idx_mask], edge_index_dst[prot_idx_mask])\n",
    "        cov_bond[prot_idx_mask] = features.bond_masks[tuple(idx)]\n",
    "        cov_bond = torch.from_numpy(cov_bond)\n",
    "        return cov_bond\n",
    "\n",
    "    def make_edge(\n",
    "        self, features: Features) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        num_atom = int(np.sum(features.atom_mask))\n",
    "        num_grids = len(features.grid_positions)\n",
    "        num_nodes = num_atom + num_grids\n",
    "\n",
    "        node_pos = np.concatenate([features.atom_positions, features.grid_positions], axis=0)\n",
    "        k_nearest = min(self.topk + 1, num_nodes)\n",
    "\n",
    "        tree = cKDTree(node_pos)\n",
    "        dd, ii = tree.query(\n",
    "            node_pos, k=k_nearest, distance_upper_bound=self.dist_cutoff\n",
    "        )\n",
    "        node_pos = torch.from_numpy(node_pos).to(torch.float32)\n",
    "        index_tensor = torch.arange(num_nodes, dtype=torch.int32)\n",
    "        edge_index_src = torch.flatten(torch.from_numpy(ii)).to(torch.int32)\n",
    "        edge_index_dst = torch.repeat_interleave(index_tensor, k_nearest)\n",
    "        dists = torch.flatten(torch.from_numpy(dd))\n",
    "\n",
    "        edge_mask = torch.logical_and(edge_index_src != edge_index_dst, edge_index_src != num_nodes)\n",
    "\n",
    "        edge_index_src = edge_index_src[edge_mask]\n",
    "        edge_index_dst = edge_index_dst[edge_mask]\n",
    "        dists = dists[edge_mask]\n",
    "\n",
    "        dist_bin = self.onehot_edge_dist(dists)\n",
    "        onehot_type = self.onehot_edge_type(edge_index_src, edge_index_dst, num_atom)\n",
    "        covalent_bond = self.cov_bond(edge_index_src, edge_index_dst, num_atom, features)\n",
    "        covalent_bond = covalent_bond.unsqueeze(-1)\n",
    "        # relative position\n",
    "        e_vec = torch.tensor(\n",
    "            node_pos[edge_index_dst.long()] - node_pos[edge_index_src.long()]\n",
    "        )\n",
    "\n",
    "        polarity_vectors = torch.tensor(\n",
    "            self.make_polarity_vector(features), dtype=torch.float32\n",
    "        )\n",
    "        # edge_type을 설정: prot-to-prot, grid-to-grid, grid-to-prot, prot-to-grid 구분\n",
    "        edge_type_prot_to_prot = (edge_index_src < num_atom) & (\n",
    "            edge_index_dst < num_atom\n",
    "        )\n",
    "        edge_type_grid_to_grid = (edge_index_src >= num_atom) & (\n",
    "            edge_index_dst >= num_atom\n",
    "        )\n",
    "        edge_type_grid_to_prot = (edge_index_src >= num_atom) & (\n",
    "            edge_index_dst < num_atom\n",
    "        )\n",
    "        edge_type_prot_to_grid = (edge_index_src < num_atom) & (\n",
    "            edge_index_dst >= num_atom\n",
    "        )\n",
    "\n",
    "        # 초기화\n",
    "        start = torch.zeros((len(edge_index_src), 3), dtype=torch.float32)\n",
    "        end = torch.zeros((len(edge_index_src), 3), dtype=torch.float32)\n",
    "\n",
    "        # 1. prot to prot 또는 grid to grid\n",
    "        mask = edge_type_prot_to_prot | edge_type_grid_to_grid\n",
    "        start[mask] = polarity_vectors[edge_index_dst[mask].long()]\n",
    "        end[mask] = polarity_vectors[edge_index_src[mask].long()]\n",
    "\n",
    "        # 2. grid to prot\n",
    "        mask = edge_type_grid_to_prot\n",
    "        start[mask] = (\n",
    "            node_pos[edge_index_src[mask].long()]\n",
    "            - node_pos[edge_index_dst[mask].long()]\n",
    "        )\n",
    "        end[mask] = polarity_vectors[edge_index_dst[mask].long()]\n",
    "\n",
    "        # 3. prot to grid\n",
    "        mask = edge_type_prot_to_grid\n",
    "        start[mask] = polarity_vectors[edge_index_src[mask].long()]\n",
    "        end[mask] = (\n",
    "            node_pos[edge_index_dst[mask].long()]\n",
    "            - node_pos[edge_index_src[mask].long()]\n",
    "        )\n",
    "\n",
    "        cos = (\n",
    "            torch.einsum(\n",
    "                \"ij,ij->i\",\n",
    "                start,\n",
    "                end,\n",
    "            ).unsqueeze(-1)\n",
    "            + self.eps\n",
    "        )\n",
    "        sin = (\n",
    "            torch.norm(\n",
    "                torch.cross(\n",
    "                    start,\n",
    "                    end,\n",
    "                ),\n",
    "                dim=1,\n",
    "                keepdim=True,\n",
    "            )\n",
    "            + self.eps\n",
    "        )\n",
    "        e_feats = torch.cat([onehot_type, dist_bin, covalent_bond, cos, sin], dim=1)\n",
    "        print(\n",
    "            \"--\",\n",
    "            onehot_type.shape,\n",
    "            dist_bin.shape,\n",
    "            covalent_bond.shape,\n",
    "            cos.shape,\n",
    "            sin.shape,\n",
    "        )\n",
    "        return edge_index_src, edge_index_dst, e_feats, e_vec\n",
    "\n",
    "    def collate(self, samples: list) -> Tuple[dgl.DGLGraph, torch.Tensor, Info]:\n",
    "        graphs, labels, g_pos, m_pos, m_types, pdb_ids = [], [], [], [], [], []\n",
    "\n",
    "        for G, L, info in samples:\n",
    "            graphs.extend(G)  # 각 샘플의 그래프 리스트를 하나의 리스트로 결합\n",
    "            labels.extend(L)  # 각 샘플의 결합된 라벨 리스트를 하나의 리스트로 결합\n",
    "            g_pos.append(info.grids_positions)\n",
    "            m_pos.append(info.metal_positions)\n",
    "            m_types.append(info.metal_types)\n",
    "            pdb_ids.append(info.pdb_id)\n",
    "        # 배치 그래프와 배치 라벨 생성\n",
    "        batched_graphs = dgl.batch(graphs)  # shape [B*N]\n",
    "        batched_labels = torch.cat(labels, dim=0)  # shape [B*N,2]\n",
    "        g_poss = torch.cat(g_pos, dim=0)\n",
    "        m_poss = torch.cat(m_pos, dim=0)\n",
    "        m_typess = torch.cat(m_types, dim=0)\n",
    "        pdb_idss = np.array(pdb_ids)\n",
    "        batched_infos = Info(\n",
    "            pdb_id=pdb_idss,\n",
    "            grids_positions=g_poss,\n",
    "            metal_positions=m_poss,\n",
    "            metal_types=m_typess,\n",
    "        )\n",
    "        return batched_graphs, batched_labels, batched_infos\n",
    "    \n",
    "    \n",
    "class OnTheFlyDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_file: str, pdb_dir: str, rf_model: str, topk: int, edge_dist_cutoff: float, pocket_dist: float, rf_threshold: float):\n",
    "        super().__init__()\n",
    "        self.data_file = Path(data_file)\n",
    "        self.pdb_dir = Path(pdb_dir)\n",
    "        self.topk = topk\n",
    "        self.edge_dist_cutoff=edge_dist_cutoff\n",
    "        self.pocket_dist=pocket_dist\n",
    "        self.rf_threshold=rf_threshold\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len()\n",
    "    \n",
    "    def __getitem__(self, index:int):\n",
    "        \n",
    "        return 1\n",
    "    \n",
    "def get_dataset_class(config):\n",
    "    dataset_type = config[\"dataset\"][\"type\"]\n",
    "    \n",
    "    if dataset_type == \"preprocessed\":\n",
    "        return PreprocessedDataSet(**config[\"dataset\"][\"preprocessed\"])\n",
    "    elif dataset_type == \"on_the_fly\":\n",
    "        return OnTheFlyDataSet(**config[\"dataset\"][\"onthefly\"])\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset type: {dataset_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ligmet.dataset import OnTheFlyDataSet\n",
    "Dataset = OnTheFlyDataSet(\n",
    "    data_file='/home/qkrgangeun/LigMet/code/src/ligmet/utils/examples/example.txt',\n",
    "    pdb_dir='/home/qkrgangeun/LigMet/code/src/ligmet/utils/examples',\n",
    "    rf_model='random_forest_model',\n",
    "    topk=16,\n",
    "    edge_dist_cutoff=3.0,\n",
    "    pocket_dist=6.0,\n",
    "    rf_threshold=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FreeSASA: warning: atom 'IPM  C1 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C2 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C3 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C4 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C5 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C6 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C7 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  O1 ' unknown, guessing element is ' O', and radius 1.520 A\n",
      "FreeSASA: warning: atom 'IPM  O2 ' unknown, guessing element is ' O', and radius 1.520 A\n",
      "FreeSASA: warning: atom 'IPM  O3 ' unknown, guessing element is ' O', and radius 1.520 A\n",
      "FreeSASA: warning: atom 'IPM  O4 ' unknown, guessing element is ' O', and radius 1.520 A\n",
      "FreeSASA: warning: atom 'IPM  O5 ' unknown, guessing element is ' O', and radius 1.520 A\n",
      "FreeSASA: warning: atom 'IPM  C1 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C2 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C3 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C4 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C5 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C6 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C7 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  O1 ' unknown, guessing element is ' O', and radius 1.520 A\n",
      "FreeSASA: warning: atom 'IPM  O2 ' unknown, guessing element is ' O', and radius 1.520 A\n",
      "FreeSASA: warning: atom 'IPM  O3 ' unknown, guessing element is ' O', and radius 1.520 A\n",
      "FreeSASA: warning: atom 'IPM  O4 ' unknown, guessing element is ' O', and radius 1.520 A\n",
      "FreeSASA: warning: atom 'IPM  O5 ' unknown, guessing element is ' O', and radius 1.520 A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max(idx) 5407\n",
      "len(features.sasas) 5408\n",
      "len(atom_names) 5408\n",
      "len(qs) 5408\n",
      "len(sec_structs) 5408\n",
      "len(gen_types) 5408\n",
      "len(bond_masks) 5408\n",
      "len(is_ligand == 1) 24\n",
      "tensor([7., 7., 7.,  ..., 9., 9., 9.])\n",
      "aatype, atomtype, atom_chemtype, sec-str, sasas, qs) torch.Size([24369, 30]) torch.Size([24369, 120]) torch.Size([24369, 62]) torch.Size([24369, 10]) torch.Size([24369, 1]) torch.Size([24369, 1])\n",
      "-- torch.Size([359490, 4]) torch.Size([359490, 7]) torch.Size([359490, 1]) torch.Size([359490, 1]) torch.Size([359490, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrgangeun/LigMet/code/src/ligmet/dataset.py:316: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  e_vec = torch.tensor(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([Graph(num_nodes=24369, num_edges=359490,\n",
       "        ndata_schemes={'xyz': Scheme(shape=(3,), dtype=torch.float32), 'L0': Scheme(shape=(224,), dtype=torch.float32), 'L1': Scheme(shape=(3,), dtype=torch.float32), 'grid_mask': Scheme(shape=(), dtype=torch.float32)}\n",
       "        edata_schemes={'L0': Scheme(shape=(14,), dtype=torch.float32), 'L1': Scheme(shape=(3,), dtype=torch.float32)})],\n",
       " [tensor([[ 0.0000, 10.0000, -7.0964, -6.6930, 33.5870],\n",
       "          [ 0.0000, 10.0000, -6.4339, -6.6930, 33.5870],\n",
       "          [ 0.0000, 10.0000, -8.5594, -6.3890, 34.3202],\n",
       "          ...,\n",
       "          [ 0.0000, 10.0000,  1.4016, -5.4000, -2.0850],\n",
       "          [ 0.0000, 10.0000,  2.0641, -5.4000, -2.0850],\n",
       "          [ 0.0000, 10.0000,  2.0151, -3.8800, -2.8967]])],\n",
       " Info(pdb_id=array('1a05_ligand', dtype='<U11'), grids_positions=tensor([[ 2.8266, 19.1820, 75.3980],\n",
       "         [ 3.4891, 19.1820, 75.3980],\n",
       "         [ 1.3636, 19.4860, 76.1312],\n",
       "         ...,\n",
       "         [ 0.3646, 20.2520, 21.6750],\n",
       "         [ 1.0271, 20.2520, 21.6750],\n",
       "         [ 0.9781, 21.7720, 20.8633]]), metal_positions=tensor([[ 9.9230, 25.8750, 41.8110],\n",
       "         [-1.0370, 25.6520, 23.7600]]), metal_types=tensor([0, 0])))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(Dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "from collections import defaultdict\n",
    "from Bio.PDB import PDBParser\n",
    "import io\n",
    "from pathlib import Path\n",
    "import ligmet.utils.pdb import read_pdb\n",
    "metals = {\"ZN\", \"MG\", \"FE\", \"CA\", \"CU\", \"MN\", \"CO\", \"NI\", \"NA\", \"K\"}  # Metal 원소 리스트\n",
    "\n",
    "\n",
    "def find_binding_residues(pdb_path, cutoff=3.0):\n",
    "    \"\"\"Metal 주변 3Å 이내의 Binding Residues를 찾는 함수\"\"\"\n",
    "    structure = read_pdb(pdb_path)\n",
    "\n",
    "    # Metal이 없는 경우 예외 처리\n",
    "    if len(structure[\"metal_positions\"]) == 0:\n",
    "        return set()\n",
    "\n",
    "    # KDTree 생성 (검색 최적화)\n",
    "    tree = cKDTree(structure[\"atom_positions\"])\n",
    "    \n",
    "    # Metal 위치 주변 cutoff 내 원자 찾기\n",
    "    binding_residues = set()\n",
    "    for metal_pos in structure[\"metal_positions\"]:\n",
    "        neigh_idx = tree.query_ball_point(metal_pos, cutoff)\n",
    "        for idx in neigh_idx:\n",
    "            res_name = structure[\"atom_residues\"][idx]\n",
    "            res_idx = structure[\"residue_idxs\"][idx]\n",
    "            binding_residues.add((res_name, res_idx))  # Residue ID까지 포함하여 저장\n",
    "\n",
    "    # Residue 이름만 반환\n",
    "    return [res_name for res_name, _ in binding_residues]\n",
    "\n",
    "# 사용 예시\n",
    "pdb_dir = Path(\"/path/to/pdb_files\")  # 실제 PDB 경로로 변경\n",
    "for pdb_file in pdb_dir.glob(\"*.pdb\"):\n",
    "    binding_residues = find_binding_residues(pdb_file)\n",
    "    print(f\"{pdb_file.stem}: {binding_residues}\")  # PDB ID와 Binding Residues 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "# 저장할 CSV 파일 경로\n",
    "output_csv = \"/home/qkrgangeun/LigMet/code/text/biolip/metal_binding_sites.csv\"\n",
    "\n",
    "# PDB 파일이 저장된 디렉토리\n",
    "pdb_dir = Path(\"/home/qkrgangeun/LigMet/code/src/ligmet/utils/examples\")  # 실제 PDB 파일 경로로 변경\n",
    "\n",
    "# 결과 저장을 위한 리스트\n",
    "data = []\n",
    "\n",
    "for pdb_file in pdb_dir.glob(\"*.pdb\"):\n",
    "    pdb_id = pdb_file.stem  # PDB ID 추출\n",
    "    structure = read_pdb(pdb_file)\n",
    "\n",
    "    # Metal이 없는 경우 건너뜀\n",
    "    if len(structure[\"metal_positions\"]) == 0:\n",
    "        continue\n",
    "\n",
    "    # Metal 원자 처리\n",
    "    for metal_pos, metal_type in zip(structure[\"metal_positions\"], structure[\"metal_types\"]):\n",
    "        binding_residues = find_binding_residues(pdb_file)\n",
    "\n",
    "        # CSV 저장 데이터 생성\n",
    "        data.append([pdb_id, metal_type, metal_pos.tolist(), binding_residues])\n",
    "\n",
    "# CSV 파일로 저장\n",
    "with open(output_csv, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"PDB ID\", \"Metal Type\", \"Metal Position\", \"Binding Residues\"])\n",
    "    for row in data:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"✅ Metal binding site 정보가 {output_csv}에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Metal 별로 포함된 PDB ID 수 ###\n",
      "MN: 1082개 PDB\n",
      "ZN: 5272개 PDB\n",
      "MG: 2290개 PDB\n",
      "CA: 4005개 PDB\n",
      "CU: 507개 PDB\n",
      "FE: 511개 PDB\n",
      "CO: 277개 PDB\n",
      "K: 25개 PDB\n",
      "NI: 28개 PDB\n",
      "\n",
      "[Metal: MN] 포함된 PDB 예시 (최대 10개):\n",
      "3v91\n",
      "6dq9\n",
      "4o7x\n",
      "5e3u\n",
      "1i3h\n",
      "4wte\n",
      "2jdz\n",
      "1yyd\n",
      "2zxp\n",
      "5ivy\n",
      "\n",
      "[Metal: ZN] 포함된 PDB 예시 (최대 10개):\n",
      "3s2l\n",
      "1xx4\n",
      "5llg\n",
      "4xgl\n",
      "1eh6\n",
      "3bkk\n",
      "1akl\n",
      "2hxv\n",
      "4oja\n",
      "6fgs\n",
      "\n",
      "[Metal: MG] 포함된 PDB 예시 (최대 10개):\n",
      "5v0d\n",
      "1ig5\n",
      "1o03\n",
      "1zet\n",
      "5m3u\n",
      "1ihu\n",
      "3u7e\n",
      "2hru\n",
      "2a31\n",
      "6bbp\n",
      "\n",
      "[Metal: CA] 포함된 PDB 예시 (최대 10개):\n",
      "1kuh\n",
      "1yzp\n",
      "6ioz\n",
      "4asm\n",
      "5xsa\n",
      "5olb\n",
      "2jhm\n",
      "5g56\n",
      "1ql9\n",
      "5b4y\n",
      "\n",
      "[Metal: CU] 포함된 PDB 예시 (최대 10개):\n",
      "1w7c\n",
      "5icu\n",
      "1jxd\n",
      "1f1d\n",
      "4x4k\n",
      "4yso\n",
      "5zll\n",
      "4dpb\n",
      "4ysp\n",
      "4hhg\n",
      "\n",
      "[Metal: FE] 포함된 PDB 예시 (최대 10개):\n",
      "6f65\n",
      "1oq9\n",
      "1qiq\n",
      "3n9t\n",
      "1s2z\n",
      "1brf\n",
      "3hhy\n",
      "4x1b\n",
      "3hfb\n",
      "5tk5\n",
      "\n",
      "[Metal: CO] 포함된 PDB 예시 (최대 10개):\n",
      "6d3j\n",
      "5yr5\n",
      "3mz7\n",
      "1mat\n",
      "1c21\n",
      "1qxw\n",
      "3a3x\n",
      "1kej\n",
      "4u6e\n",
      "3wrs\n",
      "\n",
      "[Metal: K] 포함된 PDB 예시 (최대 10개):\n",
      "4d7n\n",
      "1mei\n",
      "1krj\n",
      "1mew\n",
      "1hpm\n",
      "3fpb\n",
      "4jpf\n",
      "2fxi\n",
      "1gjv\n",
      "3zdd\n",
      "\n",
      "[Metal: NI] 포함된 PDB 예시 (최대 10개):\n",
      "2y39\n",
      "4m5b\n",
      "3kbw\n",
      "1rze\n",
      "3kco\n",
      "2gqk\n",
      "5wk0\n",
      "2gql\n",
      "1ru3\n",
      "3skd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# 파일 경로\n",
    "pdb_list_file = '/home/qkrgangeun/LigMet/code/text/biolip/filtered/train_pdbs_chain_1_filtered.txt'\n",
    "metal_data_dir = '/home/qkrgangeun/LigMet/data/biolip/metal_label/'\n",
    "\n",
    "# PDB ID 목록 읽기\n",
    "with open(pdb_list_file, 'r') as f:\n",
    "    pdb_ids = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# metal별 포함된 PDB ID 목록 저장용 딕셔너리\n",
    "metal_to_pdbs = defaultdict(set)\n",
    "\n",
    "# 각 PDB ID에 대해 metal_types 정보 수집\n",
    "for pdb_id in pdb_ids:\n",
    "    npz_path = os.path.join(metal_data_dir, f'{pdb_id}.npz')\n",
    "    if not os.path.exists(npz_path):\n",
    "        continue  # 파일이 없으면 생략\n",
    "    try:\n",
    "        data = np.load(npz_path, allow_pickle=True)\n",
    "        metal_types = data.get('metal_types', [])\n",
    "        for metal in metal_types:\n",
    "            metal_to_pdbs[metal].add(pdb_id)\n",
    "    except Exception as e:\n",
    "        print(f'Error processing {pdb_id}: {e}')\n",
    "\n",
    "# 결과 출력\n",
    "print(\"### Metal 별로 포함된 PDB ID 수 ###\")\n",
    "for metal, pdb_set in metal_to_pdbs.items():\n",
    "    print(f'{metal}: {len(pdb_set)}개 PDB')\n",
    "\n",
    "# 각 metal에 대해 포함된 PDB ID 예시 출력 (선택적)\n",
    "for metal, pdb_set in metal_to_pdbs.items():\n",
    "    print(f'\\n[Metal: {metal}] 포함된 PDB 예시 (최대 10개):')\n",
    "    for pdb_id in list(pdb_set)[:10]:\n",
    "        print(pdb_id)\n",
    "\n",
    "# 필요 시 저장 (예: metal_to_pdbs.json 등으로 저장 가능)\n",
    "# import json\n",
    "# with open('metal_to_pdbs.json', 'w') as f:\n",
    "#     json.dump({k: list(v) for k, v in metal_to_pdbs.items()}, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ metal_to_pdbs.pkl 및 pdb_id_to_metals.pkl 저장 완료.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "# 파일 경로\n",
    "pdb_list_file = '/home/qkrgangeun/LigMet/code/text/biolip/filtered/train_pdbs_chain_1_filtered.txt'\n",
    "metal_data_dir = '/home/qkrgangeun/LigMet/data/biolip/metal_label/'\n",
    "\n",
    "# PDB ID 목록 읽기\n",
    "with open(pdb_list_file, 'r') as f:\n",
    "    pdb_ids = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# metal → set(pdb_id)\n",
    "metal_to_pdbs = defaultdict(set)\n",
    "\n",
    "# PDB ID → list(metal)\n",
    "pdb_id_to_metals = defaultdict(list)\n",
    "\n",
    "# 데이터 수집\n",
    "for pdb_id in pdb_ids:\n",
    "    npz_path = os.path.join(metal_data_dir, f'{pdb_id}.npz')\n",
    "    if not os.path.exists(npz_path):\n",
    "        continue\n",
    "    try:\n",
    "        data = np.load(npz_path, allow_pickle=True)\n",
    "        metal_types = data.get('metal_types', [])\n",
    "        for metal in metal_types:\n",
    "            metal_to_pdbs[metal].add(pdb_id)\n",
    "            pdb_id_to_metals[pdb_id].append(metal)\n",
    "    except Exception as e:\n",
    "        print(f'Error processing {pdb_id}: {e}')\n",
    "\n",
    "# Pickle로 저장\n",
    "with open('/home/qkrgangeun/LigMet/data/biolip/metal_to_pdbs.pkl', 'wb') as f:\n",
    "    pickle.dump(metal_to_pdbs, f)\n",
    "\n",
    "with open('/home/qkrgangeun/LigMet/data/biolip/pdb_id_to_metals.pkl', 'wb') as f:\n",
    "    pickle.dump(pdb_id_to_metals, f)\n",
    "\n",
    "print(\"✅ metal_to_pdbs.pkl 및 pdb_id_to_metals.pkl 저장 완료.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atom_positions [[-14.514  22.336  70.118]\n",
      " [-14.169  23.759  70.137]\n",
      " [-13.261  24.184  68.955]\n",
      " ...\n",
      " [  4.067  65.245  -7.034]\n",
      " [  9.564  77.131  -5.367]\n",
      " [  4.305  51.884  -8.604]]\n",
      "atom_names ['N' 'CA' 'C' ... 'CD2' 'CL' 'CL']\n",
      "atom_elements ['N' 'C' 'C' ... 'C' 'CL' 'CL']\n",
      "atom_residues ['GLU' 'GLU' 'GLU' ... 'LEU' 'CL' 'CL']\n",
      "residue_idxs [  1   1   1 ... 368 369 370]\n",
      "chain_ids ['A' 'A' 'A' ... 'D' 'D' 'D']\n",
      "is_ligand [False False False ... False  True  True]\n",
      "metal_positions [[-14.655  35.938  50.437]\n",
      " [ -1.886  39.888  31.409]\n",
      " [  6.432  44.094  44.584]\n",
      " [ 12.504  62.446   9.381]\n",
      " [  8.933  72.885  -2.576]\n",
      " [  1.476  51.752  -7.974]\n",
      " [ -9.123  39.302  45.964]\n",
      " [ 12.179  48.498  48.131]\n",
      " [ 10.749  79.756  -6.108]\n",
      " [  5.982  57.212  -4.151]]\n",
      "metal_types ['ZN' 'ZN' 'ZN' 'ZN' 'ZN' 'ZN' 'ZN' 'ZN' 'ZN' 'ZN']\n",
      "grid_positions [[-13.816576   20.896      70.118    ]\n",
      " [-13.119152   20.896      70.118    ]\n",
      " [-15.356539   21.216      70.88983  ]\n",
      " ...\n",
      " [  8.334724   52.124     -11.167381 ]\n",
      " [  3.3470225  53.084     -10.448527 ]\n",
      " [  5.9149427  53.564      -8.016051 ]]\n",
      "sasas [4.9731144e-01 4.9011499e-02 6.1094383e-04 ... 1.1428590e+00 7.8217722e-03\n",
      " 5.0321706e-02]\n",
      "qs [-0.6046255   0.0900506   0.6884871  ... -0.28925    -0.14539966\n",
      " -0.14539966]\n",
      "sec_structs [7 7 7 ... 7 8 8]\n",
      "gen_types [15 17  4 ...  3 31 31]\n",
      "bond_masks [[    0     0     1 ... 11398 11399 11399]\n",
      " [    1  2752     2 ... 11399 11400 11401]]\n",
      "[[    0     0     1 ... 11398 11399 11399]\n",
      " [    1  2752     2 ... 11399 11400 11401]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.load(\"/home/qkrgangeun/LigMet/data/biolip/dl/features/5xwm.npz\")\n",
    "for key in data:\n",
    "    print(key, data[key])\n",
    "print(data[\"bond_masks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from ligmet.utils.pdb import read_pdb, Structure, StructureWithGrid\n",
    "from ligmet.utils.grid import *\n",
    "from ligmet.featurizer import * # type: ignore\n",
    "from openbabel import openbabel\n",
    "from dataclasses import asdict\n",
    "import traceback\n",
    "pdb_id = '5xwm'\n",
    "pdb_dir = Path(\"/home/qkrgangeun/LigMet/data/biolip/pdb\")\n",
    "pdb_path = pdb_dir / f\"{pdb_id}.pdb\"\n",
    "structure = read_pdb(pdb_path)\n",
    "pdb_io, protein_io, ligand_io = make_pdb(structure)\n",
    "ligand_pdb_str = ligand_io.getvalue()\n",
    "\n",
    "ligand_mol = None\n",
    "if ligand_pdb_str.strip():\n",
    "    ob_conversion = openbabel.OBConversion()\n",
    "    ob_conversion.SetInFormat(\"pdb\")\n",
    "    ob_mol = openbabel.OBMol()\n",
    "    ob_conversion.ReadString(ob_mol, ligand_pdb_str)\n",
    "    ligand_mol = ob_mol\n",
    "\n",
    "new_pdb_path = process_pdb(pdb_io)\n",
    "new_structure = read_pdb(new_pdb_path)\n",
    "bond_masks = cov_bonds_mask(new_structure, ligand_mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bond_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bondmask_to_neighidx(bond_mask: np.ndarray) -> np.ndarray:\n",
    "    rows, cols = np.where(np.triu(bond_mask) > 0)\n",
    "    return np.stack([rows, cols], axis=0).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     1, ..., 11398, 11399, 11399],\n",
       "       [    1,  2752,     2, ..., 11399, 11400, 11401]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = bondmask_to_neighidx(bond_masks)\n",
    "neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,     1,     1,     1],\n",
       "       [    2,     3,     4, ..., 16369, 16370, 16371]], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = bondmask_to_neighidx(neigh)\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se3_113",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
