{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch  # type: ignore\n",
    "import dgl  # type: ignore\n",
    "from scipy.spatial import cKDTree  # type: ignore\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F  # type: ignore\n",
    "from typing import Tuple, Union\n",
    "from ligmet.featurizer import Features, Info # type: ignore\n",
    "from ligmet.utils.constants import metals, standard_residues,ATOMIC_NUMBERS, atype2num,sec_struct_dict  # type: ignore\n",
    "class PreprocessedDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_file: str, features_dir: str, rf_result_dir: str,topk: 16, edge_dist_cutoff: 3.0, pocket_dist: 6.0, rf_threshold: 0.5, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.data_file=Path(data_file)\n",
    "        self.features_dir=Path(features_dir)\n",
    "        self.rf_result_dir=Path(rf_result_dir)\n",
    "        self.topk = topk\n",
    "        self.edge_dist_cutoff=edge_dist_cutoff\n",
    "        self.pocket_dist=pocket_dist\n",
    "        self.rf_threshold=rf_threshold\n",
    "        self.pdbid_lists=[pdb.strip().split(\".pdb\")[0] for pdb in open(data_file)]\n",
    "        self.eps = eps\n",
    "        self.alpha = 5.78\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pdbid_lists)\n",
    "    \n",
    "    def __getitem__(self, index:int):\n",
    "        G = []\n",
    "        L = []\n",
    "        pdb_id = self.pdbid_lists[index]\n",
    "        feature_path = self.features_dir / f\"{pdb_id}.npz\"\n",
    "        rf_result_path = self.rf_result_dir / f\"{pdb_id}.npz\"\n",
    "        data = np.load(feature_path,allow_pickle=True)\n",
    "        features = Features(\n",
    "            atom_positions=data['atom_positions'],\n",
    "            atom_names=data['atom_names'],\n",
    "            atom_elements=data['atom_elements'],\n",
    "            atom_residues=data['atom_residues'],\n",
    "            residue_idxs=data['residue_idxs'],\n",
    "            chain_ids=data['chain_ids'],\n",
    "            is_ligand=data['is_ligand'],\n",
    "            metal_positions=data['metal_positions'],\n",
    "            metal_types=data['metal_types'],\n",
    "            grid_positions=data['grid_positions'],\n",
    "            sasas=data['sasa'],\n",
    "            qs=data['qs'],\n",
    "            sec_structs=data['sec_structs'],\n",
    "            bond_masks=data['bond_masks']\n",
    "        )\n",
    "        grid_positions = features.grid_positions\n",
    "        grid_probs = np.load(rf_result_path)\n",
    "        grid_mask = grid_probs >= self.rf_threshold\n",
    "        grids_after_rf = grid_positions[grid_mask]\n",
    "        features_p, pocket_exist = self.find_pocket(features, grids_after_rf)\n",
    "        \n",
    "        if pocket_exist is False:\n",
    "            raise AttributeError(\"there is no grids after randomforest\")\n",
    "        \n",
    "        g = self.make_graph(features_p)\n",
    "        l_prob, l_type, l_vector = self.make_label(features_p)\n",
    "        labels = torch.cat([l_prob.unsqueeze(1), l_type.unsqueeze(1), l_vector], dim=1)  # shape [N,5]\n",
    "        G.append(g)\n",
    "        L.append(labels)\n",
    "        if not G:\n",
    "            raise AttributeError(f\"{pdb_id} have none type graph\")\n",
    "        info = Info(\n",
    "            pdb_id=np.array(pdb_id),\n",
    "            grids_positions=torch.tensor(grids_after_rf, dtype=torch.float32),\n",
    "            metal_positions=torch.tensor(features.metal_positions, dtype=torch.float32),\n",
    "            metal_types=torch.tensor(features.metaltype, dtype=torch.long),\n",
    "        )\n",
    "        return G, L, info\n",
    "\n",
    "    def find_pocket(self, features: Features, grids: np.ndarray):\n",
    "        c_grids = grids\n",
    "        atom_pos = features.atom_positions\n",
    "\n",
    "        gtree = cKDTree(c_grids)\n",
    "        ptree = cKDTree(atom_pos)\n",
    "        ii = gtree.query_ball_tree(ptree, self.pocket_dist)\n",
    "\n",
    "        idx = np.unique(np.concatenate([i for i in ii if i], axis=0)).astype(int)\n",
    "        if len(idx) == 0:\n",
    "            return None, False\n",
    "\n",
    "        c_features = Features(\n",
    "            atom_positions=atom_pos[idx],\n",
    "            atom_names=features.atom_names[idx],\n",
    "            atom_elements=features.atom_elements[idx],\n",
    "            atom_residues=features.atom_residues[idx],\n",
    "            residue_idxs=features.residue_idxs[idx],\n",
    "            chain_ids=features.chain_ids[idx],\n",
    "            is_ligand=features.is_ligand[idx],\n",
    "            metal_positions=features.metal_positions, \n",
    "            metal_types=features.metal_types,\n",
    "            grid_positions=c_grids,\n",
    "            sasas=features.sasas[idx],\n",
    "            qs=features.qs[idx],\n",
    "            sec_structs=features.sec_structs[idx],\n",
    "            bond_masks=features.bond_masks[np.ix_(idx, idx)], \n",
    "        )\n",
    "\n",
    "        return c_features, True\n",
    "    \n",
    "    def make_label(self, features:Features)->Union[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        grid = np.array(features.grid_positions, dtype=np.float32)\n",
    "        grids = torch.from_numpy(grid)\n",
    "        metal_pos = torch.from_numpy(features.metal_positions)\n",
    "        metal_types = torch.from_numpy(features.metaltype)\n",
    "\n",
    "        diff = grids.unsqueeze(1) - metal_pos.unsqueeze(0)  # [g,m,3]\n",
    "        dist = torch.sqrt(torch.sum(diff**2, dim=-1)) + self.eps  # [g,m]\n",
    "\n",
    "        exp_dist = torch.exp(-(dist**2) / self.alpha)\n",
    "        label_p, _ = torch.max(exp_dist, dim=-1)\n",
    "        label_prob = torch.where(label_p <= 0.1, torch.tensor(0.0), label_p)\n",
    "\n",
    "        min_dist, min_idx = torch.min(dist, dim=-1)  # [g,]\n",
    "        label_type = torch.where(\n",
    "            min_dist <= 2.0, metal_types[min_idx], torch.tensor(len(metals))\n",
    "        )\n",
    "        label_vector = diff[torch.arange(diff.size(0)), min_idx]\n",
    "        \n",
    "        return label_prob, label_type, label_vector\n",
    "    \n",
    "    def make_graph(self, features: Features) -> dgl.DGLGraph:\n",
    "        xyz = torch.tensor(np.concatenate([features.atom_positions, features.grid_positions]))\n",
    "        grid_mask = torch.ones(len(xyz))\n",
    "        grid_mask[: len(features.sasas)] = 0\n",
    "        n_feats, n_polar_vec = self.get_node_features(features)\n",
    "        num_nodes = xyz.shape[0]\n",
    "        edge_index_src, edge_index_dst, e_feats, rel_vec = self.make_edge(features)\n",
    "        G = dgl.graph((edge_index_src.to(torch.int32), edge_index_dst.to(torch.int32)),num_nodes=num_nodes)\n",
    "        G.ndata[\"xyz\"] = xyz.to(torch.float32)\n",
    "        G.ndata[\"L0\"] = n_feats.to(torch.float32)\n",
    "        G.ndata[\"L1\"] = n_polar_vec.to(torch.float32)\n",
    "        G.ndata[\"grid_mask\"] = grid_mask.to(torch.float32)\n",
    "        G.edata[\"L0\"] = e_feats.to(torch.float32)\n",
    "        G.edata[\"L1\"] = rel_vec.to(torch.float32)\n",
    "        \n",
    "        return G\n",
    "    \n",
    "    def make_polarity_vector(self, features: Features) -> np.ndarray:\n",
    "        xyz = torch.from_numpy(features.atom_positions)\n",
    "        neigh_masks = torch.from_numpy(features.bond_masks)\n",
    "\n",
    "        self_idx, nei_idx = torch.nonzero(neigh_masks, as_tuple=True)\n",
    "\n",
    "        xyz_self = xyz * neigh_masks.sum(dim=1, keepdim=True)\n",
    "        xyz_nei = -xyz[nei_idx]\n",
    "        xyz_self.scatter_add_(0, self_idx[:, None].expand(-1, 3), xyz_nei)\n",
    "\n",
    "        polar_vec = F.normalize(xyz_self, dim=1)\n",
    "        polarity_vectors = torch.cat(\n",
    "            [polar_vec, torch.zeros(features.grid_positions.shape)], dim=0\n",
    "        ).numpy()\n",
    "        return polarity_vectors\n",
    "\n",
    "    def get_node_features(self, features: Features) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # num_res = len(features.atom_names)\n",
    "        num_grids = len(features.grid_positions)\n",
    "\n",
    "        sasas = torch.from_numpy(features.sasas)\n",
    "        qs = torch.from_numpy(features.qs)\n",
    "        sec_structs = torch.from_numpy(features.sec_structs)\n",
    "        aatype = torch.from_numpy(features.atom_residues)\n",
    "        atom_chem_type = torch.from_numpy(features.atom_elements)\n",
    "        \n",
    "        # one hot features: aatype, atomtype, 2nd structures\n",
    "        # assign max int for grids\n",
    "        aatype = [standard_residues.index(res) if res in standard_residues else len(standard_residues) for res in features.atom_residues ]\n",
    "        grids_aatype = torch.ones(num_grids) * len(standard_residues)+1\n",
    "        aatype = torch.cat((aatype, grids_aatype))\n",
    "\n",
    "        atomtype = torch.from_list([ATOMIC_NUMBERS.get(elem,119) for elem in features.atom_elements])\n",
    "        grids_atomtype = torch.zeros(num_grids)\n",
    "        atomtype = torch.cat([atomtype, grids_atomtype], dim=0)\n",
    "        \n",
    "        ##TODO: ligand gentype\n",
    "        grids_atomchemtype = torch.ones(num_grids) * len(atype2num)\n",
    "        atom_chem_type = torch.cat([atom_chem_type, grids_atomchemtype], dim=0)\n",
    "        \n",
    "        grids_2nd = torch.ones(num_grids) * len(sec_struct_dict)\n",
    "        sec_structs = torch.cat([sec_structs, grids_2nd])\n",
    "\n",
    "        # one-hot encoding\n",
    "        aatype = F.one_hot(aatype.to(torch.int64), num_classes=len(standard_residues) + 2)\n",
    "        atomtype = F.one_hot(atomtype.to(torch.int64), num_classes=len(ATOMIC_NUMBERS) + 2)\n",
    "        sec_structs = F.one_hot(\n",
    "            sec_structs.to(torch.int64), num_classes=len(sec_struct_dict) + 1\n",
    "        )\n",
    "        atom_chemtype = F.one_hot(\n",
    "            atom_chem_type.to(torch.int64), num_classes=len(atype2num) + 1\n",
    "        )\n",
    "        # real value features: sasas, qs\n",
    "        # assign 0 for grids\n",
    "        grids_feat = torch.zeros(num_grids)\n",
    "        sasas = torch.cat((sasas, grids_feat)).unsqueeze(-1)\n",
    "        qs = torch.cat((qs, grids_feat)).unsqueeze(-1)\n",
    "        # sasas can have nan value\n",
    "        sasas = sasas + self.eps\n",
    "\n",
    "        n_feats = torch.cat(\n",
    "            [aatype, atomtype, atom_chemtype, sec_structs, sasas, qs], dim=1\n",
    "        )\n",
    "        print(\n",
    "            \"aatype, atomtype, atom_chemtype, sec-str, sasas, qs)\",\n",
    "            aatype.shape,\n",
    "            atomtype.shape,\n",
    "            atom_chemtype.shape,\n",
    "            sec_structs.shape,\n",
    "            sasas.shape,\n",
    "            qs.shape,\n",
    "        )\n",
    "        polarity_vectors = self.make_polarity_vector(features)\n",
    "        polarity_vectors = torch.tensor(polarity_vectors)\n",
    "        return n_feats, polarity_vectors\n",
    "\n",
    "    def onehot_edge_dist(self, dists: torch.Tensor) -> torch.Tensor:\n",
    "        bin_edges = np.arange(0, self.dist_cutoff + 0.5, 0.5)\n",
    "        dist_binned = np.digitize(dists, bins=bin_edges) - 1\n",
    "        one_hot_dist = F.one_hot(\n",
    "            torch.from_numpy(dist_binned), num_classes=len(bin_edges)\n",
    "        )\n",
    "        return one_hot_dist\n",
    "\n",
    "    def onehot_edge_type(\n",
    "        self, edge_index_src: torch.Tensor, edge_index_dst: torch.Tensor, num_atom: int\n",
    "    ) -> torch.Tensor:\n",
    "        feat = np.zeros_like(edge_index_src)  # p to p :0\n",
    "        feat[np.where((edge_index_src < num_atom) & (edge_index_dst >= num_atom))] = (\n",
    "            1  # p to g :1\n",
    "        )\n",
    "        feat[np.where((edge_index_src >= num_atom) & (edge_index_dst < num_atom))] = (\n",
    "            2  # g to p : 2\n",
    "        )\n",
    "        feat[np.where((edge_index_src >= num_atom) & (edge_index_dst >= num_atom))] = (\n",
    "            3  # g to g :3\n",
    "        )\n",
    "        one_hot_feat = F.one_hot(torch.from_numpy(feat).to(torch.int64), num_classes=4)\n",
    "        return one_hot_feat\n",
    "\n",
    "    def cov_bond(\n",
    "        self,\n",
    "        edge_index_src: torch.Tensor,\n",
    "        edge_index_dst: torch.Tensor,\n",
    "        num_atom: int,\n",
    "        features: Features,\n",
    "    ) -> torch.Tensor:\n",
    "        # shape (edge, )\n",
    "        cov_bond = np.zeros(len(edge_index_src))\n",
    "        prot_idx_mask = (edge_index_src < num_atom) & (edge_index_dst < num_atom)\n",
    "        idx = (edge_index_src[prot_idx_mask], edge_index_dst[prot_idx_mask])\n",
    "        cov_bond[prot_idx_mask] = features.bond_masks[tuple(idx)]\n",
    "        cov_bond = torch.from_numpy(cov_bond)\n",
    "        return cov_bond\n",
    "\n",
    "    def make_edge(\n",
    "        self, features: Features) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        num_atom = int(np.sum(features.atom_mask))\n",
    "        num_grids = len(features.grid_positions)\n",
    "        num_nodes = num_atom + num_grids\n",
    "\n",
    "        node_pos = np.concatenate([features.atom_positions, features.grid_positions], axis=0)\n",
    "        k_nearest = min(self.topk + 1, num_nodes)\n",
    "\n",
    "        tree = cKDTree(node_pos)\n",
    "        dd, ii = tree.query(\n",
    "            node_pos, k=k_nearest, distance_upper_bound=self.dist_cutoff\n",
    "        )\n",
    "        node_pos = torch.from_numpy(node_pos).to(torch.float32)\n",
    "        index_tensor = torch.arange(num_nodes, dtype=torch.int32)\n",
    "        edge_index_src = torch.flatten(torch.from_numpy(ii)).to(torch.int32)\n",
    "        edge_index_dst = torch.repeat_interleave(index_tensor, k_nearest)\n",
    "        dists = torch.flatten(torch.from_numpy(dd))\n",
    "\n",
    "        edge_mask = torch.logical_and(edge_index_src != edge_index_dst, edge_index_src != num_nodes)\n",
    "\n",
    "        edge_index_src = edge_index_src[edge_mask]\n",
    "        edge_index_dst = edge_index_dst[edge_mask]\n",
    "        dists = dists[edge_mask]\n",
    "\n",
    "        dist_bin = self.onehot_edge_dist(dists)\n",
    "        onehot_type = self.onehot_edge_type(edge_index_src, edge_index_dst, num_atom)\n",
    "        covalent_bond = self.cov_bond(edge_index_src, edge_index_dst, num_atom, features)\n",
    "        covalent_bond = covalent_bond.unsqueeze(-1)\n",
    "        # relative position\n",
    "        e_vec = torch.tensor(\n",
    "            node_pos[edge_index_dst.long()] - node_pos[edge_index_src.long()]\n",
    "        )\n",
    "\n",
    "        polarity_vectors = torch.tensor(\n",
    "            self.make_polarity_vector(features), dtype=torch.float32\n",
    "        )\n",
    "        # edge_type을 설정: prot-to-prot, grid-to-grid, grid-to-prot, prot-to-grid 구분\n",
    "        edge_type_prot_to_prot = (edge_index_src < num_atom) & (\n",
    "            edge_index_dst < num_atom\n",
    "        )\n",
    "        edge_type_grid_to_grid = (edge_index_src >= num_atom) & (\n",
    "            edge_index_dst >= num_atom\n",
    "        )\n",
    "        edge_type_grid_to_prot = (edge_index_src >= num_atom) & (\n",
    "            edge_index_dst < num_atom\n",
    "        )\n",
    "        edge_type_prot_to_grid = (edge_index_src < num_atom) & (\n",
    "            edge_index_dst >= num_atom\n",
    "        )\n",
    "\n",
    "        # 초기화\n",
    "        start = torch.zeros((len(edge_index_src), 3), dtype=torch.float32)\n",
    "        end = torch.zeros((len(edge_index_src), 3), dtype=torch.float32)\n",
    "\n",
    "        # 1. prot to prot 또는 grid to grid\n",
    "        mask = edge_type_prot_to_prot | edge_type_grid_to_grid\n",
    "        start[mask] = polarity_vectors[edge_index_dst[mask].long()]\n",
    "        end[mask] = polarity_vectors[edge_index_src[mask].long()]\n",
    "\n",
    "        # 2. grid to prot\n",
    "        mask = edge_type_grid_to_prot\n",
    "        start[mask] = (\n",
    "            node_pos[edge_index_src[mask].long()]\n",
    "            - node_pos[edge_index_dst[mask].long()]\n",
    "        )\n",
    "        end[mask] = polarity_vectors[edge_index_dst[mask].long()]\n",
    "\n",
    "        # 3. prot to grid\n",
    "        mask = edge_type_prot_to_grid\n",
    "        start[mask] = polarity_vectors[edge_index_src[mask].long()]\n",
    "        end[mask] = (\n",
    "            node_pos[edge_index_dst[mask].long()]\n",
    "            - node_pos[edge_index_src[mask].long()]\n",
    "        )\n",
    "\n",
    "        cos = (\n",
    "            torch.einsum(\n",
    "                \"ij,ij->i\",\n",
    "                start,\n",
    "                end,\n",
    "            ).unsqueeze(-1)\n",
    "            + self.eps\n",
    "        )\n",
    "        sin = (\n",
    "            torch.norm(\n",
    "                torch.cross(\n",
    "                    start,\n",
    "                    end,\n",
    "                ),\n",
    "                dim=1,\n",
    "                keepdim=True,\n",
    "            )\n",
    "            + self.eps\n",
    "        )\n",
    "        e_feats = torch.cat([onehot_type, dist_bin, covalent_bond, cos, sin], dim=1)\n",
    "        print(\n",
    "            \"--\",\n",
    "            onehot_type.shape,\n",
    "            dist_bin.shape,\n",
    "            covalent_bond.shape,\n",
    "            cos.shape,\n",
    "            sin.shape,\n",
    "        )\n",
    "        return edge_index_src, edge_index_dst, e_feats, e_vec\n",
    "\n",
    "    def collate(self, samples: list) -> Tuple[dgl.DGLGraph, torch.Tensor, Info]:\n",
    "        graphs, labels, g_pos, m_pos, m_types, pdb_ids = [], [], [], [], [], []\n",
    "\n",
    "        for G, L, info in samples:\n",
    "            graphs.extend(G)  # 각 샘플의 그래프 리스트를 하나의 리스트로 결합\n",
    "            labels.extend(L)  # 각 샘플의 결합된 라벨 리스트를 하나의 리스트로 결합\n",
    "            g_pos.append(info.grids_positions)\n",
    "            m_pos.append(info.metal_positions)\n",
    "            m_types.append(info.metal_types)\n",
    "            pdb_ids.append(info.pdb_id)\n",
    "        # 배치 그래프와 배치 라벨 생성\n",
    "        batched_graphs = dgl.batch(graphs)  # shape [B*N]\n",
    "        batched_labels = torch.cat(labels, dim=0)  # shape [B*N,2]\n",
    "        g_poss = torch.cat(g_pos, dim=0)\n",
    "        m_poss = torch.cat(m_pos, dim=0)\n",
    "        m_typess = torch.cat(m_types, dim=0)\n",
    "        pdb_idss = np.array(pdb_ids)\n",
    "        batched_infos = Info(\n",
    "            pdb_id=pdb_idss,\n",
    "            grids_positions=g_poss,\n",
    "            metal_positions=m_poss,\n",
    "            metal_types=m_typess,\n",
    "        )\n",
    "        return batched_graphs, batched_labels, batched_infos\n",
    "    \n",
    "    \n",
    "class OnTheFlyDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_file: str, pdb_dir: str, rf_model: str, topk: int, edge_dist_cutoff: float, pocket_dist: float, rf_threshold: float):\n",
    "        super().__init__()\n",
    "        self.data_file = Path(data_file)\n",
    "        self.pdb_dir = Path(pdb_dir)\n",
    "        self.topk = topk\n",
    "        self.edge_dist_cutoff=edge_dist_cutoff\n",
    "        self.pocket_dist=pocket_dist\n",
    "        self.rf_threshold=rf_threshold\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len()\n",
    "    \n",
    "    def __getitem__(self, index:int):\n",
    "        \n",
    "        return 1\n",
    "    \n",
    "def get_dataset_class(config):\n",
    "    dataset_type = config[\"dataset\"][\"type\"]\n",
    "    \n",
    "    if dataset_type == \"preprocessed\":\n",
    "        return PreprocessedDataSet(**config[\"dataset\"][\"preprocessed\"])\n",
    "    elif dataset_type == \"on_the_fly\":\n",
    "        return OnTheFlyDataSet(**config[\"dataset\"][\"onthefly\"])\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset type: {dataset_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ligmet.dataset import OnTheFlyDataSet\n",
    "Dataset = OnTheFlyDataSet(\n",
    "    data_file='/home/qkrgangeun/LigMet/code/src/ligmet/utils/examples/example.txt',\n",
    "    pdb_dir='/home/qkrgangeun/LigMet/code/src/ligmet/utils/examples',\n",
    "    rf_model='random_forest_model',\n",
    "    topk=16,\n",
    "    edge_dist_cutoff=3.0,\n",
    "    pocket_dist=6.0,\n",
    "    rf_threshold=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FreeSASA: warning: atom 'IPM  C1 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C2 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C3 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C4 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C5 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C6 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C7 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  O1 ' unknown, guessing element is ' O', and radius 1.520 A\n",
      "FreeSASA: warning: atom 'IPM  O2 ' unknown, guessing element is ' O', and radius 1.520 A\n",
      "FreeSASA: warning: atom 'IPM  O3 ' unknown, guessing element is ' O', and radius 1.520 A\n",
      "FreeSASA: warning: atom 'IPM  O4 ' unknown, guessing element is ' O', and radius 1.520 A\n",
      "FreeSASA: warning: atom 'IPM  O5 ' unknown, guessing element is ' O', and radius 1.520 A\n",
      "FreeSASA: warning: atom 'IPM  C1 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C2 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C3 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C4 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C5 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C6 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  C7 ' unknown, guessing element is ' C', and radius 1.700 A\n",
      "FreeSASA: warning: atom 'IPM  O1 ' unknown, guessing element is ' O', and radius 1.520 A\n",
      "FreeSASA: warning: atom 'IPM  O2 ' unknown, guessing element is ' O', and radius 1.520 A\n",
      "FreeSASA: warning: atom 'IPM  O3 ' unknown, guessing element is ' O', and radius 1.520 A\n",
      "FreeSASA: warning: atom 'IPM  O4 ' unknown, guessing element is ' O', and radius 1.520 A\n",
      "FreeSASA: warning: atom 'IPM  O5 ' unknown, guessing element is ' O', and radius 1.520 A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max(idx) 5407\n",
      "len(features.sasas) 5408\n",
      "len(atom_names) 5408\n",
      "len(qs) 5408\n",
      "len(sec_structs) 5408\n",
      "len(gen_types) 5408\n",
      "len(bond_masks) 5408\n",
      "len(is_ligand == 1) 24\n",
      "tensor([7., 7., 7.,  ..., 9., 9., 9.])\n",
      "aatype, atomtype, atom_chemtype, sec-str, sasas, qs) torch.Size([24369, 30]) torch.Size([24369, 120]) torch.Size([24369, 62]) torch.Size([24369, 10]) torch.Size([24369, 1]) torch.Size([24369, 1])\n",
      "-- torch.Size([359490, 4]) torch.Size([359490, 7]) torch.Size([359490, 1]) torch.Size([359490, 1]) torch.Size([359490, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrgangeun/LigMet/code/src/ligmet/dataset.py:316: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  e_vec = torch.tensor(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([Graph(num_nodes=24369, num_edges=359490,\n",
       "        ndata_schemes={'xyz': Scheme(shape=(3,), dtype=torch.float32), 'L0': Scheme(shape=(224,), dtype=torch.float32), 'L1': Scheme(shape=(3,), dtype=torch.float32), 'grid_mask': Scheme(shape=(), dtype=torch.float32)}\n",
       "        edata_schemes={'L0': Scheme(shape=(14,), dtype=torch.float32), 'L1': Scheme(shape=(3,), dtype=torch.float32)})],\n",
       " [tensor([[ 0.0000, 10.0000, -7.0964, -6.6930, 33.5870],\n",
       "          [ 0.0000, 10.0000, -6.4339, -6.6930, 33.5870],\n",
       "          [ 0.0000, 10.0000, -8.5594, -6.3890, 34.3202],\n",
       "          ...,\n",
       "          [ 0.0000, 10.0000,  1.4016, -5.4000, -2.0850],\n",
       "          [ 0.0000, 10.0000,  2.0641, -5.4000, -2.0850],\n",
       "          [ 0.0000, 10.0000,  2.0151, -3.8800, -2.8967]])],\n",
       " Info(pdb_id=array('1a05_ligand', dtype='<U11'), grids_positions=tensor([[ 2.8266, 19.1820, 75.3980],\n",
       "         [ 3.4891, 19.1820, 75.3980],\n",
       "         [ 1.3636, 19.4860, 76.1312],\n",
       "         ...,\n",
       "         [ 0.3646, 20.2520, 21.6750],\n",
       "         [ 1.0271, 20.2520, 21.6750],\n",
       "         [ 0.9781, 21.7720, 20.8633]]), metal_positions=tensor([[ 9.9230, 25.8750, 41.8110],\n",
       "         [-1.0370, 25.6520, 23.7600]]), metal_types=tensor([0, 0])))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(Dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se3_113",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
