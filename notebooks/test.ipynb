{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import io\n",
    "from collections import defaultdict\n",
    "from Bio.PDB.PDBParser import PDBParser\n",
    "from ligmet.utils.constants import metals\n",
    "\n",
    "@dataclass\n",
    "class Structure:\n",
    "    atom_positions: np.ndarray  # [n_atoms, 3]\n",
    "    atom_names: np.ndarray  # [n_atoms, 1]\n",
    "    atom_elements: np.ndarray  # [n_atoms, 1]\n",
    "    atom_residues: np.ndarray  # [n_atoms, 1] if ligand: x\n",
    "    residue_idxs: np.ndarray #[n_atoms, 1]\n",
    "    is_ligand: np.ndarray  # [n_atoms, 1]\n",
    "    metal_positions: np.ndarray  # [n_metals, 3]\n",
    "    metal_types: np.ndarray  # [n_metals, 1]\n",
    "\n",
    "@dataclass\n",
    "class StructureWithGrid:\n",
    "    atom_positions: np.ndarray  # [n_atoms, 3]\n",
    "    atom_names: np.ndarray  # [n_atoms, 1]\n",
    "    atom_elements: np.ndarray  # [n_atoms, 1]\n",
    "    atom_residues: np.ndarray  # [n_atoms, 1] if ligand: x\n",
    "    residue_idxs: np.ndarray #[n_atoms, 1]\n",
    "    is_ligand: np.ndarray  # [n_atoms, 1]\n",
    "    metal_positions: np.ndarray  # [n_metals, 3]\n",
    "    metal_types: np.ndarray  # [n_metals, 1]\n",
    "    grid_positions: np.ndarray #[n_grids, 3]\n",
    "    \n",
    "def read_pdb(pdb_path) -> Structure:\n",
    "    with open(pdb_path, \"r\") as f:\n",
    "        pdb_str = f.read()\n",
    "    pdb_fh = io.StringIO(pdb_str)\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure(\"none\", pdb_fh)\n",
    "    model = list(structure.get_models())[0]\n",
    "\n",
    "    data = defaultdict(list)\n",
    "\n",
    "    for chain in model:\n",
    "        for res in chain:\n",
    "            if res.id[2] != \" \":\n",
    "                raise ValueError(f\"Insertion code found at chain {chain.id}, residue {res.id[1]}\")\n",
    "            if res.id[0] == \" \":  # ATOM\n",
    "                for atom in res:\n",
    "                    data[\"atom_positions\"].append(atom.coord)\n",
    "                    data[\"atom_elements\"].append(atom.element)\n",
    "                    data[\"atom_residues\"].append(res.get_resname())\n",
    "                    data[\"atom_names\"].append(atom.name)\n",
    "                    data[\"is_ligand\"].append(0)\n",
    "                    data[\"residue_idxs\"].append(res.get_id()[1])\n",
    "            elif \"H_\" in res.id[0]:  # HETATM except water (which starts with \"W_\")\n",
    "                for atom in res.get_atoms():\n",
    "                    if atom.element in metals:\n",
    "                        data[\"metal_positions\"].append(atom.coord)\n",
    "                        data[\"metal_types\"].append(atom.element)\n",
    "                    else:  # Ligand\n",
    "                        data[\"atom_positions\"].append(atom.coord)\n",
    "                        data[\"atom_elements\"].append(atom.element)\n",
    "                        data[\"atom_residues\"].append(res.get_resname())\n",
    "                        data[\"atom_names\"].append(atom.name)\n",
    "                        data[\"is_ligand\"].append(1)\n",
    "                        data[\"residue_idxs\"].append(res.get_id()[1])\n",
    "\n",
    "\n",
    "    return Structure(**{k: np.array(v) for k, v in data.items()})\n",
    "\n",
    "st = read_pdb('/home/qkrgangeun/LigMet/code/src/ligmet/utils/1a05_ligand.pdb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5408, 3)\n",
      "(5408,)\n",
      "(5408,)\n",
      "(5408,)\n",
      "(5408,)\n"
     ]
    }
   ],
   "source": [
    "print(st.atom_positions.shape)\n",
    "print(st.atom_elements.shape)\n",
    "print(st.atom_residues.shape)\n",
    "print(st.residue_idxs.shape)\n",
    "print(st.is_ligand.shape)\n",
    "# st.metal_positions\n",
    "# st.metal_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n",
      "['MET' 'MET' 'MET' ... 'MET' 'MET' 'MET']\n"
     ]
    }
   ],
   "source": [
    "mask = st.is_ligand\n",
    "print(mask)\n",
    "print(st.atom_residues[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n",
      "['MET' 'MET' 'MET' ... 'IPM' 'IPM' 'IPM']\n"
     ]
    }
   ],
   "source": [
    "print(mask)\n",
    "print(st.atom_residues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 1918 occurrences\n",
      "1: 2306 occurrences\n",
      "2: 160 occurrences\n",
      "3: 1212 occurrences\n",
      "4: 188 occurrences\n",
      "5: 29 occurrences\n",
      "6: 81 occurrences\n",
      "7: 130 occurrences\n",
      "8: 17 occurrences\n",
      "9: 0 occurrences\n",
      "10: 0 occurrences\n",
      "11: 0 occurrences\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# 로그 파일 경로 설정\n",
    "log_file = '/home/qkrgangeun/LigMet/sh/0403/test2.log'\n",
    "\n",
    "# \"type label tensor(..., device='cuda:0')\" 형태의 문자열에서 대괄호 안의 숫자들을 추출하기 위한 정규표현식\n",
    "pattern = re.compile(r\"tensor\\(\\[([0-9,\\s]+)\\],\\s*device='cuda:0'\\)\")\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "with open(log_file, 'r') as file:\n",
    "    for line in file:\n",
    "        # 해당 줄에 관심 있는 문자열이 포함되어 있는 경우에 한해 처리합니다.\n",
    "        if \"type label tensor\" in line:\n",
    "            match = pattern.search(line)\n",
    "            if match:\n",
    "                # 대괄호 안의 문자열 추출 (숫자와 쉼표, 공백)\n",
    "                numbers_str = match.group(1)\n",
    "                # 쉼표를 기준으로 나눈 후 정수로 변환\n",
    "                numbers = [int(item.strip()) for item in numbers_str.split(',') if item.strip().isdigit()]\n",
    "                counter.update(numbers)\n",
    "\n",
    "# 0부터 11까지 각 숫자의 등장 빈도 출력\n",
    "for num in range(12):\n",
    "    print(f\"{num}: {counter[num]} occurrences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal Type 별 빈도수:\n",
      "Metal Type\n",
      "ZN    34358\n",
      "CA    28560\n",
      "MG    17566\n",
      "MN     8274\n",
      "FE     4763\n",
      "CU     4171\n",
      "CO     1515\n",
      "NI      319\n",
      "K       271\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "file_path = '/home/qkrgangeun/LigMet/code/text/biolip/metal_binding_sites3.csv'\n",
    "\n",
    "# CSV 파일을 DataFrame으로 읽어옵니다.\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# \"Metal Type\" 컬럼의 값에 대해 빈도수를 계산합니다.\n",
    "metal_counts = df['Metal Type'].value_counts()\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Metal Type 별 빈도수:\")\n",
    "print(metal_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation - precision,recall test: chain1_pre, posweight 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_id = '5s8q'\n",
    "result_file = f'/home/qkrgangeun/LigMet/data/biolip/test/0507_rf/{pdb_id}.npz'\n",
    "grid_file = f'/home/qkrgangeun/LigMet/data/biolip/dl/features/{pdb_id}.npz'\n",
    "threshold = 0.5\n",
    "\n",
    "data = np.load(result_file)\n",
    "feature = np.load(grid_file)\n",
    "pred = data['pred']\n",
    "type_pred = data['type_pred']\n",
    "label = data['label']\n",
    "type_label = data['type_label']    \n",
    "metal_positions = data['metal_positions']\n",
    "metal_types = data['metal_types']\n",
    "grid = feature['grid_positions']\n",
    "# position recall\n",
    "def write_pdb_with_grids(\n",
    "    pdb_id,\n",
    "    metal_positions,\n",
    "    grid_positions,\n",
    "    grid_predictions,\n",
    "    grid_type_predictions,\n",
    "    pdb_input_dir,\n",
    "    pdb_output_dir,\n",
    "    pred_threshold=0.5,\n",
    "):\n",
    "    \"\"\"\n",
    "    1) 원본 PDB 파일(pdb_id.pdb)을 읽어서\n",
    "    2) metal pred >= pred_threshold 를 만족하는 grid 좌표에 대해\n",
    "       HETATM 라인을 추가해 저장.\n",
    "    \"\"\"\n",
    "    os.makedirs(pdb_output_dir, exist_ok=True)\n",
    "\n",
    "    input_pdb_path = os.path.join(pdb_input_dir, f\"{pdb_id}.pdb\")\n",
    "    output_pdb_path = os.path.join(pdb_output_dir, f\"{pdb_id}.pdb\")\n",
    "\n",
    "    if not os.path.exists(input_pdb_path):\n",
    "        print(f\"[WARNING] {input_pdb_path} not found. Skipping.\")\n",
    "        return\n",
    "\n",
    "    with open(input_pdb_path, \"r\") as infile:\n",
    "        pdb_lines = []\n",
    "        for line in infile:\n",
    "            if line.startswith(\"ATOM\") or line.startswith(\"HETATM\"):\n",
    "                pdb_lines.append(line)\n",
    "\n",
    "    with open(output_pdb_path, \"w\") as outfile:\n",
    "        # 1) 기존 PDB 내용 먼저 기록\n",
    "        for line in pdb_lines:\n",
    "            outfile.write(line)\n",
    "\n",
    "        # 2) 조건을 만족하는 그리드 좌표 기록\n",
    "        start_idx = 0  # 임의로 레지듀 번호 시작\n",
    "        for idx, (grid_pos, grid_pred, grid_type_pred) in enumerate(\n",
    "            zip(grid_positions, grid_predictions, grid_type_predictions)\n",
    "        ):\n",
    "            if grid_pred >= pred_threshold:\n",
    "                metal_type_idx = torch.argmax(torch.tensor(grid_type_pred)).item()\n",
    "                if metal_type_idx < len(metals):\n",
    "                    metal_type = metals[metal_type_idx]\n",
    "                else:\n",
    "                    metal_type = \"UNK\"\n",
    "\n",
    "                atom_idx = start_idx + idx\n",
    "                x, y, z = grid_pos\n",
    "                outfile.write(\n",
    "                    f\"HETATM{atom_idx:>5}  {metal_type:>3} GRD A{atom_idx:>4}    \"\n",
    "                    f\"{x:8.3f}{y:8.3f}{z:8.3f}  {grid_pred:.2f}  0.00           {metal_type}\\n\"\n",
    "                )\n",
    "\n",
    "    print(f\"[INFO] Saved PDB with grids: {output_pdb_path}\")\n",
    "\n",
    "\n",
    "# ========== 모든 PDB에 대해 write_pdb_with_grids 수행 ==========\n",
    "def save_all_pdb_with_grids(results, infos, pdb_input_dir, pdb_output_dir):\n",
    "    \"\"\"\n",
    "    각 샘플별로 write_pdb_with_grids()를 호출하여\n",
    "    pred >= 특정 threshold 만족하는 그리드를 HETATM으로 기록\n",
    "    \"\"\"\n",
    "    for i, info in enumerate(infos):\n",
    "        pdb_id = info.pdb_id[0]\n",
    "        metal_positions = info.metal_positions.cpu().numpy()\n",
    "        grid_positions = info.grids_positions.cpu().numpy()\n",
    "        grid_predictions = results[i][0].cpu().numpy()  # pred\n",
    "        grid_type_preds = results[i][1].cpu().numpy()  # type_pred\n",
    "\n",
    "        write_pdb_with_grids(\n",
    "            pdb_id,\n",
    "            metal_positions,\n",
    "            grid_positions,\n",
    "            grid_predictions,\n",
    "            grid_type_preds,\n",
    "            pdb_input_dir,\n",
    "            pdb_output_dir,\n",
    "            pred_threshold=0.0,  # 필요에 따라 수정\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 로그 파일 경로\n",
    "log_path = \"/home/qkrgangeun/LigMet/benchmark/test_chain1_pre3.log\"\n",
    "\n",
    "# 그룹 분류용 딕셔너리 초기화\n",
    "group_precision_recall = {\n",
    "    \"A\": [],  # recall > 0.7 and precision > 0.5\n",
    "    \"B\": [],  # recall > 0.7 and precision <= 0.5\n",
    "    \"C\": [],  # recall <= 0.7 and precision > 0.5\n",
    "    \"D\": [],  # recall <= 0.7 and precision <= 0.5\n",
    "}\n",
    "\n",
    "group_type_accuracy = {\n",
    "    \"HIGH\": [],  # type_accuracy > 0.5\n",
    "    \"LOW\": []    # type_accuracy <= 0.5\n",
    "}\n",
    "\n",
    "with open(log_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "pdb_id = None\n",
    "for i, line in enumerate(lines):\n",
    "    # PDB ID 찾기\n",
    "    if line.startswith(\"=== PDB:\"):\n",
    "        pdb_id_match = re.search(r\"\\['(.+?)'\\]\", line)\n",
    "        if pdb_id_match:\n",
    "            pdb_id = pdb_id_match.group(1)\n",
    "\n",
    "    # precision & recall 값 찾기\n",
    "    if pdb_id and \"threshold 0.5 | precision:\" in line:\n",
    "        pr_match = re.search(r\"precision: ([0-9.]+) \\| recall: ([0-9.]+)\", line)\n",
    "        if pr_match:\n",
    "            precision = float(pr_match.group(1))\n",
    "            recall = float(pr_match.group(2))\n",
    "            # 그룹 분류\n",
    "            if recall > 0.7:\n",
    "                if precision > 0.5:\n",
    "                    group_precision_recall[\"A\"].append(pdb_id)\n",
    "                else:\n",
    "                    group_precision_recall[\"B\"].append(pdb_id)\n",
    "            else:\n",
    "                if precision > 0.5:\n",
    "                    group_precision_recall[\"C\"].append(pdb_id)\n",
    "                else:\n",
    "                    group_precision_recall[\"D\"].append(pdb_id)\n",
    "\n",
    "    # type_accuracy 값 찾기\n",
    "    if pdb_id and \"threshold 0.5 | type_accuracy:\" in line:\n",
    "        acc_match = re.search(r\"type_accuracy: ([0-9.]+)\", line)\n",
    "        if acc_match:\n",
    "            type_acc = float(acc_match.group(1))\n",
    "            if type_acc > 0.5:\n",
    "                group_type_accuracy[\"HIGH\"].append(pdb_id)\n",
    "            else:\n",
    "                group_type_accuracy[\"LOW\"].append(pdb_id)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"=== Precision/Recall 그룹 ===\")\n",
    "for group, ids in group_precision_recall.items():\n",
    "    print(f\"Group {group}: {ids}\")\n",
    "\n",
    "print(\"\\n=== Type Accuracy 그룹 ===\")\n",
    "for group, ids in group_type_accuracy.items():\n",
    "    print(f\"{group}: {ids}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se3_113",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
